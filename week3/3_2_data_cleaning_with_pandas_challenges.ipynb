{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning with Pandas\n",
        "\n",
        "In this notebook we'll go through a few basic data cleaning steps that should be performed on all new datasets where necessary.\n",
        "\n",
        "We'll go through the process with both the `orders` and `orderlines` datasets. You can then practice these skills by cleaning the `products` dataset yourself"
      ],
      "metadata": {
        "id": "kYo4UvcCvkUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FgRIdUs1vcZ8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# orders.csv\n",
        "url = \"https://drive.google.com/file/d/1Vu0q91qZw6lqhIqbjoXYvYAQTmVHh6uZ/view?usp=sharing\" \n",
        "path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n",
        "orders = pd.read_csv(path)\n",
        "\n",
        "# orderlines.csv\n",
        "url = \"https://drive.google.com/file/d/1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG/view?usp=sharing\" \n",
        "path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n",
        "orderlines = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "_87JoNgVviOG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the best ways to begin data cleaning is by exploring using `.info()`. This will tell us:\n",
        "* The shape of the DataFrame\n",
        "* The names of the columns\n",
        "* If there are any missing values\n",
        "* The datatypes of the columns\n",
        "\n",
        "By exploring the missing values and correcting any incorrect datatypes, we often come across inconsistencies in our data.\n",
        "\n",
        "Beyond this, we should also have a **check for any duplicate rows**. \n",
        "\n",
        "Let's first deal with the duplicates, as it's nice and easy, then we'll explore what `.info()` has to tell us."
      ],
      "metadata": {
        "id": "fVLitYX1yhc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.&nbsp; Duplicates\n",
        "We can check for duplicates using the pandas [.duplicated()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) method. \n",
        "\n",
        "We can then delete these rows, if we wish, using [.drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)"
      ],
      "metadata": {
        "id": "036ciQ6rwBJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# orders\n",
        "orders.duplicated().sum()"
      ],
      "metadata": {
        "id": "6dVkoUu7wC-b",
        "outputId": "15d529cd-7efd-4e4f-e7e0-c4d91c5a0cdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# orderlines\n",
        "orderlines.duplicated().sum()"
      ],
      "metadata": {
        "id": "iaeAQB_3whli",
        "outputId": "638cd23a-e7c9-41da-c132-b9b94d3fd464",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have no duplicate rows in either DataFrame. Easy, there is no problem to solve. Normally though, if there were some duplicates, we'd drop the extra rows."
      ],
      "metadata": {
        "id": "3LbnJquF0vRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.&nbsp; `.info()`"
      ],
      "metadata": {
        "id": "9lX7YbHlzoEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders.info()"
      ],
      "metadata": {
        "id": "_AAsMOTS2L9r",
        "outputId": "20e8109b-c50c-4b38-cfaa-fa336f570f71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 226909 entries, 0 to 226908\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   order_id      226909 non-null  int64  \n",
            " 1   created_date  226909 non-null  object \n",
            " 2   total_paid    226904 non-null  float64\n",
            " 3   state         226909 non-null  object \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 6.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `total_paid` has 5 missing values\n",
        "* `created_date` should become datetime datatype"
      ],
      "metadata": {
        "id": "Txm3Bv952UCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orderlines.info()"
      ],
      "metadata": {
        "id": "kvDA-z032Rm2",
        "outputId": "149e052a-43d8-41bc-b0b2-858bafdbd24d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 293983 entries, 0 to 293982\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   id                293983 non-null  int64 \n",
            " 1   id_order          293983 non-null  int64 \n",
            " 2   product_id        293983 non-null  int64 \n",
            " 3   product_quantity  293983 non-null  int64 \n",
            " 4   sku               293983 non-null  object\n",
            " 5   unit_price        293983 non-null  object\n",
            " 6   date              293983 non-null  object\n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 15.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `date` should be a datetime datatype\n",
        "* `unit_price` should be a float datatype"
      ],
      "metadata": {
        "id": "iLSpYm1G2sPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.&nbsp; Missing values"
      ],
      "metadata": {
        "id": "MlwJt5c-wiQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.&nbsp; Orders\n",
        "* `total_paid` has 5 missing values"
      ],
      "metadata": {
        "id": "63eKHGzJwkuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"5 missing values represents {((orders.total_paid.isna().sum() / orders.shape[0])*100).round(5)}% of the rows in our DataFrame\")"
      ],
      "metadata": {
        "id": "Yh81k3ppwl37",
        "outputId": "90cbf8dd-e84e-4a19-edb5-531367ddc1f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 missing values represents 0.0022% of the rows in our DataFrame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there is such a tiny amount of missing values, we will simply delete these rows, as we have enough data without them."
      ],
      "metadata": {
        "id": "eMW6J-4v_iVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders = orders.loc[~orders.total_paid.isna(), :]"
      ],
      "metadata": {
        "id": "ohcl2Pb2B_Ch"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Should you have a significant number of missing values in the future, you have a choice: \n",
        "+ you can impute the values\n",
        "+ you can take the values from other DataFrames, if they are present there\n",
        "+ you can delete the values\n",
        "+ or any number of other creative solutions\n",
        "\n",
        "Please, always consider how much time you have on your project, and what impact your method of choice will have on your final assesment."
      ],
      "metadata": {
        "id": "AIWAR4xI_3jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.&nbsp; Orderlines\n",
        "There are no missing values in `orderlines`"
      ],
      "metadata": {
        "id": "nziIE3hbwmNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.&nbsp; Datatypes"
      ],
      "metadata": {
        "id": "_feog1aCwosJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.&nbsp; Orders\n",
        "* `created_date` should become datetime datatype"
      ],
      "metadata": {
        "id": "wCJyQYkOwrBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders[\"created_date\"] = pd.to_datetime(orders[\"created_date\"])"
      ],
      "metadata": {
        "id": "cF9roGlewr8j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.&nbsp; Orderlines\n",
        "* `date` should be a datetime datatype\n",
        "* `unit_price` should be a float datatype"
      ],
      "metadata": {
        "id": "osvynBTNwsin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.1.&nbsp; `date`"
      ],
      "metadata": {
        "id": "PJcuKn8K06Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orderlines[\"date\"] = pd.to_datetime(orderlines[\"date\"])"
      ],
      "metadata": {
        "id": "FnXgRKERwtvS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.2.&nbsp;`unit_price`"
      ],
      "metadata": {
        "id": "F7i78NDY0-oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orderlines[\"unit_price\"] = pd.to_numeric(orderlines[\"unit_price\"])"
      ],
      "metadata": {
        "id": "iOFBNmuRDuGU",
        "outputId": "aaa6eec7-1a11-4418-b08d-b159a5beace4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"1.137.99\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ddce6c16f698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morderlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_price\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morderlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"1.137.99\" at position 6"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see when we try to convert `unit_price` to a numerical datatype, we receive a `ValueError` telling us that pandas doesn't understand the number `1.137.99`. This is probably because numbers cannot have 2 decimal points. Let's see if there are any other numbers like this."
      ],
      "metadata": {
        "id": "xEqhP5RFSmRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orderlines.unit_price.str.contains(\"\\d+\\.\\d+\\.\\d+\").value_counts()"
      ],
      "metadata": {
        "id": "ONy-oCt0SkrR",
        "outputId": "561209c4-ed77-4b2f-ac4b-eba66e896ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d428903af45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morderlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\d+\\.\\d+\\.\\d+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like over 36000 rows in `orderlines` are affected by this problem. Let's work out how much that is as a percentage of our total data."
      ],
      "metadata": {
        "id": "HSUPvFJU6Jv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_dot_percentage = ((orderlines.unit_price.str.contains(\"\\d+\\.\\d+\\.\\d+\").value_counts()[1] / orderlines.shape[0])*100).round(2)\n",
        "print(f\"The 2 dot problem represents {two_dot_percentage}% of the rows in our DataFrame\")"
      ],
      "metadata": {
        "id": "r75Rm1EgVjpi",
        "outputId": "023d4861-6ec7-4efc-b266-8dd5aa1e747d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2 dot problem represents 12.3% of the rows in our DataFrame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a bit of a tricky decision as 12.3% is a significant amount of our data... and we might even end up losing a larger portion of our data than this too. For the moment we will delete the rows as we only have 2 weeks for this project and I'd like some quick, accurate results to show. If we have time at the end, we can come back and investigate this problem further, maybe there's a solution?\n",
        "\n",
        "Each row of `orderlines` represents a product in an order. For example, if order number 175 contained 3 seperate products, then order 175 would have 3 rows in `orderlines`, one row for each of the products. If 2 of those products have 'normal' prices (14.99, 15.85) and 1 has a price with 2 decimal points (1.137.99), we need to remove the whole order and not just the affected row. If we only remove the row with 2 decimal places then any later analysis about products and prices could be misleading.\n",
        "\n",
        "We therefore need to find the order numbers associated with the rows that have 2 decimal points, and then remove all the associated rows."
      ],
      "metadata": {
        "id": "5Kp9_4pqeu5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_dot_order_ids_list = orderlines.loc[orderlines.unit_price.str.contains(\"\\d+\\.\\d+\\.\\d+\"), \"id_order\"]\n",
        "orderlines = orderlines.loc[~orderlines.id_order.isin(two_dot_order_ids_list)]"
      ],
      "metadata": {
        "id": "wQnSe-n1WCqv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orderlines.shape[0]"
      ],
      "metadata": {
        "id": "k-GLzXuV0Ioj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We still have 216250 rows in orderlines to work with. This should be more than enough for our evaluation.\n",
        "\n",
        "Now that all of the 2 decimal point prices have been removed, let's try again to convert the column `unit_price` to the correct datatype."
      ],
      "metadata": {
        "id": "2pd5t4110iz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orderlines[\"unit_price\"] = pd.to_numeric(orderlines[\"unit_price\"])\n",
        "orderlines.info()"
      ],
      "metadata": {
        "id": "Q4eDTAPs1HMZ",
        "outputId": "9d02ab3e-8268-4c26-81ce-45b532b52eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 216250 entries, 0 to 293982\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype         \n",
            "---  ------            --------------   -----         \n",
            " 0   id                216250 non-null  int64         \n",
            " 1   id_order          216250 non-null  int64         \n",
            " 2   product_id        216250 non-null  int64         \n",
            " 3   product_quantity  216250 non-null  int64         \n",
            " 4   sku               216250 non-null  object        \n",
            " 5   unit_price        216250 non-null  float64       \n",
            " 6   date              216250 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), float64(1), int64(4), object(1)\n",
            "memory usage: 13.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It worked perfectly"
      ],
      "metadata": {
        "id": "sBudIQLm6oJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge: Clean the `products` DataFrame\n",
        "Now it's your turn. Use the lessons you learnt above and clean the products DataFrame. You don't have to copy exactly what we did. Think about the consequences of your actions, sometimes it is ok to delete rows, other times you may wish to come up with more creative solutions."
      ],
      "metadata": {
        "id": "1zGAzgIX8_-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# products.csv\n",
        "url = \"https://drive.google.com/file/d/1afxwDXfl-7cQ_qLwyDitfcCx3u7WMvkU/view?usp=sharing\" \n",
        "path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n",
        "products = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "LtYqdFsa9KTS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "products.info(show_counts=True)"
      ],
      "metadata": {
        "id": "UW3zYoni9Vcy",
        "outputId": "288922f5-950a-41d5-e1ef-5fe4790cd725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19326 entries, 0 to 19325\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   sku          19326 non-null  object\n",
            " 1   name         19326 non-null  object\n",
            " 2   desc         19319 non-null  object\n",
            " 3   price        19280 non-null  object\n",
            " 4   promo_price  19326 non-null  object\n",
            " 5   in_stock     19326 non-null  int64 \n",
            " 6   type         19276 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Look for Duplicates"
      ],
      "metadata": {
        "id": "DyTfC-WY-IWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# products.duplicated().sum()\n",
        "df = products.drop_duplicates()\n",
        "df.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "MXZXRvUa_GTW",
        "outputId": "b9af5151-c22c-45f2-83a3-15c934d9932b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Look for Missing values\n"
      ],
      "metadata": {
        "id": "XTGqkqtm--ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "df.isna().sum()\n",
        "# print('df isna %i'%df.isna().sum())\n",
        "\n",
        "df = df.dropna()\n",
        "# print('price isna %i'%df.isna().sum())\n",
        "# df.head(5)"
      ],
      "metadata": {
        "id": "_LrT0QGlkKi-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check / Change Data types"
      ],
      "metadata": {
        "id": "4x6xeGDu_B0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "two_dot_percentage = df.price.str.contains(\"\\d+\\.\\d+\\.\\d+\").value_counts()[1]\n",
        "print('contains two dots: %i'%(two_dot_percentage))\n",
        "two_dot_price_list = df.loc[df.price.str.contains(\"\\d+\\.\\d+\\.\\d+\"), \"price\"]\n",
        "products_cl = df.loc[~df.price.isin(two_dot_price_list)]\n",
        "products_cl[\"price\"] = pd.to_numeric(products_cl[\"price\"],errors='coerce')\n",
        "products_cl[\"promo_price\"] = pd.to_numeric(products_cl[\"promo_price\"],errors='coerce')\n",
        "\n",
        "display(products_cl.info())\n",
        "display(products.info())\n"
      ],
      "metadata": {
        "id": "3evkDaafvFUq",
        "outputId": "9d21981b-124a-4550-bbe1-8d798935a81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contains two dots: 373\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10104 entries, 0 to 19325\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   sku          10104 non-null  object \n",
            " 1   name         10104 non-null  object \n",
            " 2   desc         10104 non-null  object \n",
            " 3   price        10104 non-null  float64\n",
            " 4   promo_price  5820 non-null   float64\n",
            " 5   in_stock     10104 non-null  int64  \n",
            " 6   type         10104 non-null  object \n",
            "dtypes: float64(2), int64(1), object(4)\n",
            "memory usage: 631.5+ KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-0ad5628ff67e>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  products_cl[\"price\"] = pd.to_numeric(products_cl[\"price\"],errors='coerce')\n",
            "<ipython-input-57-0ad5628ff67e>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  products_cl[\"promo_price\"] = pd.to_numeric(products_cl[\"promo_price\"],errors='coerce')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19326 entries, 0 to 19325\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   sku          19326 non-null  object\n",
            " 1   name         19326 non-null  object\n",
            " 2   desc         19319 non-null  object\n",
            " 3   price        19280 non-null  object\n",
            " 4   promo_price  19326 non-null  object\n",
            " 5   in_stock     19326 non-null  int64 \n",
            " 6   type         19276 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 1.0+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}